{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../support/')\n",
    "from scipy.ndimage.measurements import label\n",
    "from scipy.ndimage import interpolation\n",
    "from time import time\n",
    "from glob import glob\n",
    "import timeit\n",
    "from os.path import join, basename, isfile\n",
    "from tqdm import tqdm\n",
    "from paths import *\n",
    "from ct_reader import *\n",
    "import dicom\n",
    "from scipy.misc import imresize\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "from paths import *\n",
    "from scipy.ndimage import morphology\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ISO, JVASK, JPLUR:  \n",
    "\n",
    "    amount\n",
    "    max\n",
    "    std\n",
    "    mean\n",
    "    median\n",
    "    amount <= 2\n",
    "    2 <= amount < 4\n",
    "    4 <= amount < 6\n",
    "    8 <= amount < 10\n",
    "    8 <= amount < 10\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_ct(path, ret_xy_spacing=False):\n",
    "    patient = read_ct_scan(path)\n",
    "    image = get_pixels_hu(patient)\n",
    "    image[image == image[0,0,0]] = 0\n",
    "    \n",
    "    if ret_xy_spacing:\n",
    "        try:\n",
    "            return image, patient[0].PixelSpacing[0]\n",
    "        except AttributeError:\n",
    "            return image, scan.GetSpacing()[0]\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_nodules(enhanced):\n",
    "    isolated = enhanced.copy()\n",
    "    isolated[(isolated == 4)\n",
    "            |(isolated == 2)\n",
    "            |(isolated == 6)] = 0\n",
    "    isolated, _ = label(isolated)\n",
    "\n",
    "    vascular = enhanced.copy()\n",
    "    vascular[(vascular == 1)\n",
    "            |(vascular == 2)\n",
    "            |(vascular == 3)] = 0\n",
    "    vascular, _ = label(vascular)\n",
    "\n",
    "    plural = enhanced.copy()\n",
    "    plural[(plural == 1)\n",
    "          |(plural == 4)\n",
    "          |(plural == 5)] = 0\n",
    "    plural, _ = label(plural)\n",
    "    return isolated, vascular, plural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mask_features(mask,sp_mask):\n",
    "    volumes = concatenate((bincount(mask.flatten()),zeros(18)))\n",
    "    zone_volumes = bincount(sp_mask.flatten())\n",
    "    ans = dict()\n",
    "    for i in range(16):\n",
    "        try:\n",
    "            ans['volume' + str(i)] = volumes[i]\n",
    "        except:\n",
    "            ans['volume' + str(i)] = 0 \n",
    "    for i in range(7):\n",
    "        ans['z_volume' + str(i)] = zone_volumes[i]\n",
    "    ans['l//r'] = volumes[1]  / volumes[2] if(volumes[2]) else 0.0\n",
    "    ans['lungoverlap//l'] = volumes[3] / volumes[1] if(volumes[1]) else 0.0\n",
    "    ans['br_overlap//l'] = volumes[5] / volumes[1] if(volumes[1]) else 0.0\n",
    "    ans['br_overlap//r'] = volumes[6] / volumes[2] if(volumes[2]) else 0.0\n",
    "    ans['tr_overlap//l'] = volumes[9] / volumes[1] if(volumes[1]) else 0.0\n",
    "    ans['tr_overlap//r'] = volumes[10] / volumes[2] if(volumes[2]) else 0.0\n",
    "    ans['br_tr_overlap//tr'] = volumes[12] / volumes[8] if(volumes[8]) else 0.0\n",
    "    ans['z_volume_1//2'] = zone_volumes[1] / zone_volumes[2]\n",
    "    ans['z_volume_2//3'] = zone_volumes[2] / zone_volumes[3]\n",
    "    ans['z_volume_4//5'] = zone_volumes[4] / zone_volumes[5]\n",
    "    ans['z_volume_5//6'] = zone_volumes[5] / zone_volumes[6]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def if_left(mask):\n",
    "    return in1d(mask,[1,3,5,7,9,11,13,15]).reshape(mask.shape)\n",
    "            \n",
    "def if_right(mask):\n",
    "    return in1d(mask,[2,3,6,7,10,11,14,15]).reshape(mask.shape)\n",
    "\n",
    "def split_mask(mask):\n",
    "    mn1 = where(if_left(mask))[0].min()\n",
    "    mx1 = where(if_left(mask))[0].max()\n",
    "    mn2 = where(if_right(mask))[0].min()\n",
    "    mx2 = where(if_right(mask))[0].max()\n",
    "    height1 = int((mx1-mn1)/3.0)\n",
    "    height2 = int((mx2-mn2)/3.0)\n",
    "    mask_zones = zeros(mask.shape)\n",
    "    mask_zones[mn1:mn1+height1,:,:] = 1 \n",
    "    mask_zones[mn1+height1:mn1+2*height1,:,:] = 2\n",
    "    mask_zones[mn1+2*height1:mx1,:,:] = 3\n",
    "    mask_l = if_left(mask)*mask_zones\n",
    "    mask_zones = zeros(mask.shape)\n",
    "    mask_zones[mn2:mn2+height2,:,:] = 4\n",
    "    mask_zones[mn2+height2:mn2+2*height2,:,:] = 5\n",
    "    mask_zones[mn2+2*height2:mx2,:,:] = 6\n",
    "    return (mask_l + if_right(mask) * mask_zones).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge(enhanced,mask):\n",
    "    return 8*mask+enhanced\n",
    "def unmerge(merged_mask):\n",
    "    return merged_mask%8, merged_mask//8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collect_stats(enhanced,mask,sp_mask):\n",
    "    prev_time = time()\n",
    "    l_enhanced = enhanced * if_left(mask)\n",
    "    r_enhanced = enhanced * if_right(mask)\n",
    " \n",
    "    \n",
    "#     print('split_mask ',time()-prev_time)\n",
    "#     prev_time = time()\n",
    "    \n",
    "    enh_areas = bincount(enhanced.flatten())[1:]\n",
    "    enh_l_areas = bincount(l_enhanced.flatten())[1:]\n",
    "    enh_r_areas = bincount(r_enhanced.flatten())[1:]\n",
    "    \n",
    "    enh_areas_zones = list()\n",
    "    for i in range(1,7):\n",
    "        enh_areas_zones.append(bincount((enhanced * (sp_mask == i)).flatten())[1:])\n",
    "#     enh_l_areas = concatenate((enh_areas_zones[1][enh_areas_zones[1]>0],\n",
    "#                               enh_areas_zones[2][enh_areas_zones[2]>0],\n",
    "#                               enh_areas_zones[0][enh_areas_zones[0]>0]))\n",
    "#     enh_r_areas = concatenate((enh_areas_zones[4][enh_areas_zones[4]>0],\n",
    "#                               enh_areas_zones[5][enh_areas_zones[5]>0],\n",
    "#                               enh_areas_zones[3][enh_areas_zones[3]>0]))\n",
    "#     enh_areas = concatenate((enh_l_areas,enh_r_areas))\n",
    "#     print('bincounts ',time()-prev_time)\n",
    "#     prev_time = time()\n",
    "    \n",
    "    if not enh_areas.shape[0]:\n",
    "        max_areas = dict()\n",
    "        for i in range(5):\n",
    "            max_areas['max'+str(i)] = 0\n",
    "            max_areas['max_l'+str(i)] = 0\n",
    "            max_areas['max_r'+str(i)] = 0\n",
    "        zone_feats = dict()\n",
    "        for i in range(6):\n",
    "            zone_feats['amoun_z' + str(i+1)] = 0\n",
    "            zone_feats['sumarea_z' + str(i+1)] = 0\n",
    "        enh_comps_after_dil = dict()\n",
    "        for i in range(20):\n",
    "            enh_comps_after_dil['comps_dil'+str(i)] = 0\n",
    "            enh_comps_after_dil['comps_dil_l'+str(i)] = 0\n",
    "            enh_comps_after_dil['comps_dil_r'+str(i)] = 0\n",
    "        ans = dict((('areas', 0), ('amoun', 0), \n",
    "                     ('mean', 0), ('std', 0), ('median', 0), \n",
    "                     ('mean_not_min', 0), \n",
    "                     ('median_not_min', 0), \n",
    "                     ('modes', [0] * 9)))\n",
    "        ans.update(max_areas)\n",
    "        ans.update(enh_comps_after_dil)\n",
    "        ans.update(mask_features(mask,sp_mask))\n",
    "        ans.update(zone_feats)\n",
    "        return ans\n",
    "    \n",
    "    enh_amoun = enh_areas[enh_areas > 0].shape[0]\n",
    "    enh_amoun_l = enh_l_areas[enh_l_areas > 0].shape[0]\n",
    "    enh_amoun_r = enh_r_areas[enh_r_areas > 0].shape[0]\n",
    "    enh_amoun_zones = [x[x > 0].shape[0] for x in enh_areas_zones]\n",
    "    enh_area_sum_zones = [x[x > 0].sum() for x in enh_areas_zones]\n",
    "    \n",
    "    zone_feats = dict()\n",
    "    for i in range(6):\n",
    "        zone_feats['amoun_z' + str(i+1)] = enh_amoun_zones[i]\n",
    "        zone_feats['sumarea_z' + str(i+1)] = enh_area_sum_zones[i]\n",
    "    \n",
    "    enh_mean = mean(enh_areas)\n",
    "    enh_std = std(enh_areas)\n",
    "    enh_sort_areas = sorted(enh_areas[enh_areas > 0],reverse=True)\n",
    "    enh_sort_areas_l = sorted(enh_l_areas[enh_l_areas > 0],reverse=True)\n",
    "    enh_sort_areas_r = sorted(enh_r_areas[enh_r_areas > 0],reverse=True)\n",
    "    max_areas = dict()\n",
    "    for i in range(5):\n",
    "        try:\n",
    "            max_areas['max'+str(i)] = enh_sort_areas[i]\n",
    "        except:\n",
    "            max_areas['max'+str(i)] = 0 \n",
    "        try:\n",
    "            max_areas['max_l'+str(i)] = enh_sort_areas_l[i]\n",
    "        except:\n",
    "            max_areas['max_l'+str(i)] = 0    \n",
    "        try:\n",
    "            max_areas['max_r'+str(i)] = enh_sort_areas_r[i]\n",
    "        except:\n",
    "            max_areas['max_l'+str(i)] = 0\n",
    "    \n",
    "    enh_median = median(enh_areas)\n",
    "    enh_mean_not_min = enh_areas[enh_areas != enh_areas.min()].mean()\n",
    "    enh_median_not_min = median(enh_areas[enh_areas != enh_areas.min()])\n",
    "    modes = [2, 3, 4, 5, 6, 9, 12, 19, 37, 1e7]\n",
    "    enh_modes = [sum((enh_areas >= modes[i - 1]) \n",
    "                 & (modes[i] > enh_areas))\n",
    "                for i in range(1, len(modes))]\n",
    "    \n",
    "#     print('stats ',time()-prev_time)\n",
    "#     prev_time = time()\n",
    "    \n",
    "    img = enhanced.copy()\n",
    "    enh_comps_after_dil = dict()\n",
    "    iter_num = 1\n",
    "    for i in range(iter_num):\n",
    "        labeled,label_num = label(img)\n",
    "        enh_comps_after_dil['comps_dil'+str(i)] = label_num\n",
    "        enh_comps_after_dil['comps_dil_l'+str(i)] = len(unique(labeled*if_left(mask)))\n",
    "        enh_comps_after_dil['comps_dil_r'+str(i)] = len(unique(labeled*if_right(mask)))\n",
    "        img = morphology.binary_dilation(img,structure=ones((5,5,5)))\n",
    "    labeled,label_num = label(img)\n",
    "    enh_comps_after_dil['comps_dil'+str(iter_num)] = label_num\n",
    "    enh_comps_after_dil['comps_dil_l'+str(iter_num)] = len(unique(labeled*if_left(mask)))\n",
    "    enh_comps_after_dil['comps_dil_r'+str(iter_num)] = len(unique(labeled*if_right(mask)))\n",
    "\n",
    "#     print('dil ',time()-prev_time)\n",
    "#     prev_time = time()\n",
    "    \n",
    "    \n",
    "    ans = dict((('areas', sum(enh_areas)), ('amoun', enh_amoun), \n",
    "                 ('mean', enh_mean), ('std', enh_std), ('median', enh_median), \n",
    "                 ('mean_not_min', enh_mean_not_min), \n",
    "                 ('median_not_min', enh_median_not_min),\n",
    "                 ('modes', enh_modes)))\n",
    "    ans.update(max_areas)\n",
    "    ans.update(enh_comps_after_dil)\n",
    "    ans.update(mask_features(mask,sp_mask))\n",
    "    ans.update(zone_feats)\n",
    "\n",
    "#     print('mask_feats ',time()-prev_time)\n",
    "#     prev_time = time()\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-e657c5079265>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'COMBINED'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menhanced\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0misolated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvascular\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplural\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_nodules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menhanced\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0msp_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0misolated_stats\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollect_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misolated\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msp_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mvascular_stats\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollect_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvascular\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msp_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-54d752e554fa>\u001b[0m in \u001b[0;36msplit_mask\u001b[1;34m(mask)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msplit_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmn1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mif_left\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mmx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mif_left\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmn2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mif_right\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/a.dobrenkii/anaconda3/lib/python3.5/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "patients = set([basename(path) for path in glob(join(PATH['DATA'], '*'))])\n",
    "patients = patients.difference(set(pickle.load(open(join(PATH['WEIGHTS'], 'erroneus'), 'rb'))))\n",
    "patients = list(patients)\n",
    "patients = ['4dbda61d574417c7f25d6e9a8f0749a7']\n",
    "isolated_stats = list()\n",
    "vascular_stats = list()\n",
    "plural_stats = list()\n",
    "for i, path in tqdm(enumerate(patients)):\n",
    "    enhanced = load(join(PATH['DATA_ENHANCED'], \n",
    "                         path + '.npy'))\n",
    "    mask = load(join(PATH['DATA_OUT'], \n",
    "                         path + '.npy'))\n",
    "    if mask.max() > 15:\n",
    "        enhanced,mask = unmerge(mask)\n",
    "    else:\n",
    "        zoomfactor = [w/float(f) for w,f in zip(enhanced.shape,mask.shape)]\n",
    "        mask = interpolation.zoom(mask,zoom=zoomfactor,order = 0,mode = 'nearest')\n",
    "        save(join(PATH['COMBINED'],path),merge(enhanced,mask))\n",
    "    isolated, vascular, plural = label_nodules(enhanced)\n",
    "    sp_mask = split_mask(mask)\n",
    "    isolated_stats += [(path, collect_stats(isolated,mask,sp_mask))]\n",
    "    vascular_stats += [(path, collect_stats(vascular,mask,sp_mask))]\n",
    "    plural_stats += [(path, collect_stats(plural,mask,sp_mask))]\n",
    "#     if i % 100 == 0:\n",
    "#         pickle.dump(isolated_stats, open(join(PATH['DATA_OUT'], 'isolated_stats'), 'wb'))\n",
    "#         pickle.dump(vascular_stats, open(join(PATH['DATA_OUT'], 'vascular_stats'), 'wb'))\n",
    "#         pickle.dump(plural_stats, open(join(PATH['DATA_OUT'], 'plural_stats'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(join(PATH['DATA_OUT'],'DATAFRAMES','crashes.txt')) as f:\n",
    "    pats = [pat.strip() for pat in f.readlines()]\n",
    "    pats = [pat for pat in pats if pat!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 12], dtype=int8)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '4dbda61d574417c7f25d6e9a8f0749a7'\n",
    "mask = load(join(PATH['DATA_OUT'], \n",
    "                         path + '.npy'))\n",
    "enhanced,mask = unmerge(mask)\n",
    "# sp_mask = split_mask(mask)\n",
    "unique(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([281, 281, 281, 281, 282, 282, 282, 282, 283, 283, 283, 283, 283,\n",
       "        283, 284, 284, 284, 284, 284, 284, 285, 285, 285, 285, 285, 285,\n",
       "        286, 286, 286, 286, 286, 286, 286, 286, 286, 286, 286, 286, 286,\n",
       "        286, 286, 287, 287, 287, 287, 287, 287, 287, 287, 287, 287, 287,\n",
       "        287, 287, 287, 287, 288, 288, 288, 288, 288, 288, 288, 288, 288,\n",
       "        288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288,\n",
       "        289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289,\n",
       "        289, 289, 289, 289, 289, 289, 289, 289, 289, 290, 290, 290, 290,\n",
       "        290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290,\n",
       "        290, 290, 290, 290, 290, 291, 292]),\n",
       " array([176, 176, 177, 177, 176, 176, 177, 177, 174, 174, 176, 176, 177,\n",
       "        177, 174, 174, 176, 176, 177, 177, 174, 174, 176, 176, 177, 177,\n",
       "        173, 174, 174, 174, 174, 175, 175, 175, 175, 175, 176, 176, 176,\n",
       "        177, 177, 173, 174, 174, 174, 174, 175, 175, 175, 175, 175, 176,\n",
       "        176, 176, 177, 177, 172, 172, 173, 173, 174, 174, 174, 174, 174,\n",
       "        174, 174, 175, 175, 175, 175, 175, 175, 175, 175, 176, 176, 176,\n",
       "        172, 172, 173, 173, 174, 174, 174, 174, 174, 174, 174, 175, 175,\n",
       "        175, 175, 175, 175, 175, 175, 176, 176, 176, 172, 172, 173, 173,\n",
       "        174, 174, 174, 174, 174, 174, 174, 175, 175, 175, 175, 175, 175,\n",
       "        175, 175, 176, 176, 176, 172, 172]),\n",
       " array([184, 185, 184, 185, 184, 185, 184, 185, 184, 185, 184, 185, 183,\n",
       "        184, 184, 185, 184, 185, 183, 184, 184, 185, 184, 185, 183, 184,\n",
       "        185, 181, 182, 183, 185, 177, 178, 183, 184, 185, 182, 183, 184,\n",
       "        182, 183, 185, 181, 182, 183, 185, 177, 178, 183, 184, 185, 182,\n",
       "        183, 184, 182, 183, 184, 185, 184, 185, 178, 179, 180, 182, 183,\n",
       "        184, 185, 176, 177, 178, 179, 180, 181, 182, 183, 180, 181, 182,\n",
       "        184, 185, 184, 185, 178, 179, 180, 182, 183, 184, 185, 176, 177,\n",
       "        178, 179, 180, 181, 182, 183, 180, 181, 182, 184, 185, 184, 185,\n",
       "        178, 179, 180, 182, 183, 184, 185, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 180, 181, 182, 184, 184]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def operate(path):\n",
    "    enhanced = load(join(PATH['DATA_ENHANCED'], \n",
    "                         path + '.npy'))\n",
    "    mask = load(join(PATH['DATA_OUT'], \n",
    "                         path + '.npy'))\n",
    "    zoomfactor = [w/float(f) for w,f in zip(enhanced.shape,mask.shape)]\n",
    "    mask = interpolation.zoom(mask,zoom=zoomfactor,order = 0,mode = 'nearest')\n",
    "    isolated, vascular, plural = label_nodules(enhanced)\n",
    "    sp_mask = split_mask(mask)\n",
    "    save(join(PATH['COMBINED'],path),merge(enhanced,mask))\n",
    "    return (path, collect_stats(isolated,mask,sp_mask)),\\\n",
    "            (path, collect_stats(vascular,mask,sp_mask)),\\\n",
    "            (path, collect_stats(plural,mask,sp_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patients = set([basename(path) for path in glob(join(PATH['DATA'], '*'))])\n",
    "patients = patients.difference(set(pickle.load(open(join(PATH['WEIGHTS'], 'erroneus'), 'rb'))))\n",
    "patients = list(patients)\n",
    "stats = list()\n",
    "with Pool(10) as p:\n",
    "    stats = p.map(operate,patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(stats, open(join(PATH['DATA_OUT'], 'merged_stats'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zoomfactor = [w/float(f) for w,f in zip(enhanced.shape,mask.shape)]\n",
    "zmask = interpolation.zoom(mask,zoom=zoomfactor,order = 0,mode = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_dataframe(stats):\n",
    "    columns = ['id', 'max', \n",
    "               'amoun', 'mean', \n",
    "               'median_not_min', \n",
    "               'mean_not_min', \n",
    "               'std', 'areas', \n",
    "               'median'] + ['modes_' + str(i) \n",
    "                            for i in range(9)]\n",
    "\n",
    "    df = pd.DataFrame(None, columns=columns)\n",
    "    \n",
    "    for isolated in tqdm(stats):\n",
    "        tmp = dict()\n",
    "        if 'modes' in  isolated[1].keys():\n",
    "            isolated[1]['modes'] = [sum(threshold)\n",
    "                                    for threshold in isolated[1]['modes']]\n",
    "        else: \n",
    "            isolated[1]['modes'] = [0] * 9\n",
    "            \n",
    "        for i in range(9):\n",
    "            tmp['modes_' + str(i)] = [isolated[1]['modes'][i]]\n",
    "        tmp['id'] = isolated[0]\n",
    "        tmp['areas'] = [sum(isolated[1]['areas'])]\n",
    "        remind = set(isolated_stats[0][1].keys())\n",
    "        remind = remind.difference(['modes', 'areas'])\n",
    "        for key in remind:\n",
    "            tmp[key] = [isolated[1][key]]\n",
    "        df = df.append(pd.DataFrame(tmp))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = join(PATH['STAGE_MASKS'], 'DATAFRAMES')\n",
    "merge_stats = pickle.load(open(join(path, 'merged_stats'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iso_list, vas_list, plu_list = zip(*merge_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 360/360 [00:04<00:00, 74.05it/s]\n"
     ]
    }
   ],
   "source": [
    "merged_lists = [(iso_item[0], iso_item[1], vas_item[1], plu_item[1]) \n",
    "                for iso_item in tqdm(iso_list)\n",
    "                for vas_item in vas_list \n",
    "                for plu_item in plu_list \n",
    "                if iso_item[0] == vas_item[0] and plu_item[0] == vas_item[0] and iso_item[1] is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_list = list()\n",
    "for (patient, iso_stats, vas_stats, plu_stats) in merged_lists:\n",
    "    new_dict = {'id' : patient}\n",
    "    for item in iso_stats.items():\n",
    "        new_dict['iso_' + item[0]] = item[1]\n",
    "    for item in vas_stats.items():\n",
    "        new_dict['vas_' + item[0]] = item[1]\n",
    "    for item in plu_stats.items():\n",
    "        new_dict['plu_' + item[0]] = item[1]\n",
    "    dict_list.append(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(join(PATH['STAGE_MASKS'],\n",
    "               'DATAFRAMES', \n",
    "               'stats_not_full.csv'), 'w') as fd:\n",
    "    pd.DataFrame(dict_list).to_csv(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>iso_amoun</th>\n",
       "      <th>iso_amoun_z1</th>\n",
       "      <th>iso_amoun_z2</th>\n",
       "      <th>iso_amoun_z3</th>\n",
       "      <th>iso_amoun_z4</th>\n",
       "      <th>iso_amoun_z5</th>\n",
       "      <th>iso_amoun_z6</th>\n",
       "      <th>iso_areas</th>\n",
       "      <th>...</th>\n",
       "      <th>vas_z_volume1</th>\n",
       "      <th>vas_z_volume2</th>\n",
       "      <th>vas_z_volume3</th>\n",
       "      <th>vas_z_volume4</th>\n",
       "      <th>vas_z_volume5</th>\n",
       "      <th>vas_z_volume6</th>\n",
       "      <th>vas_z_volume_1//2</th>\n",
       "      <th>vas_z_volume_2//3</th>\n",
       "      <th>vas_z_volume_4//5</th>\n",
       "      <th>vas_z_volume_5//6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cf7afab6741f4175c6aae2536749b89f</td>\n",
       "      <td>201</td>\n",
       "      <td>25</td>\n",
       "      <td>47</td>\n",
       "      <td>43</td>\n",
       "      <td>28</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>5238</td>\n",
       "      <td>...</td>\n",
       "      <td>535765</td>\n",
       "      <td>1104333</td>\n",
       "      <td>762003</td>\n",
       "      <td>488646</td>\n",
       "      <td>968148</td>\n",
       "      <td>488200</td>\n",
       "      <td>0.485148</td>\n",
       "      <td>1.449250</td>\n",
       "      <td>0.504722</td>\n",
       "      <td>1.983097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6202db4b61c151e3e1d86cf5d3a75877</td>\n",
       "      <td>196</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>5290</td>\n",
       "      <td>...</td>\n",
       "      <td>475975</td>\n",
       "      <td>1204535</td>\n",
       "      <td>562326</td>\n",
       "      <td>434793</td>\n",
       "      <td>838418</td>\n",
       "      <td>597108</td>\n",
       "      <td>0.395152</td>\n",
       "      <td>2.142058</td>\n",
       "      <td>0.518587</td>\n",
       "      <td>1.404131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>370f849df7e2b4570548158dfc63a90c</td>\n",
       "      <td>797</td>\n",
       "      <td>114</td>\n",
       "      <td>179</td>\n",
       "      <td>144</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>143</td>\n",
       "      <td>19509</td>\n",
       "      <td>...</td>\n",
       "      <td>641479</td>\n",
       "      <td>1235065</td>\n",
       "      <td>742397</td>\n",
       "      <td>666509</td>\n",
       "      <td>1001041</td>\n",
       "      <td>619150</td>\n",
       "      <td>0.519389</td>\n",
       "      <td>1.663618</td>\n",
       "      <td>0.665816</td>\n",
       "      <td>1.616799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4870509d75603c7bd809595252a984d8</td>\n",
       "      <td>181</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>4265</td>\n",
       "      <td>...</td>\n",
       "      <td>544285</td>\n",
       "      <td>971626</td>\n",
       "      <td>285907</td>\n",
       "      <td>487694</td>\n",
       "      <td>797550</td>\n",
       "      <td>381174</td>\n",
       "      <td>0.560180</td>\n",
       "      <td>3.398399</td>\n",
       "      <td>0.611490</td>\n",
       "      <td>2.092352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>63248fdafd2df302b57a479289d76105</td>\n",
       "      <td>449</td>\n",
       "      <td>75</td>\n",
       "      <td>116</td>\n",
       "      <td>52</td>\n",
       "      <td>72</td>\n",
       "      <td>97</td>\n",
       "      <td>58</td>\n",
       "      <td>11678</td>\n",
       "      <td>...</td>\n",
       "      <td>571762</td>\n",
       "      <td>1263324</td>\n",
       "      <td>654674</td>\n",
       "      <td>632676</td>\n",
       "      <td>1133022</td>\n",
       "      <td>662144</td>\n",
       "      <td>0.452585</td>\n",
       "      <td>1.929699</td>\n",
       "      <td>0.558397</td>\n",
       "      <td>1.711141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                id  iso_amoun  iso_amoun_z1  \\\n",
       "0           0  cf7afab6741f4175c6aae2536749b89f        201            25   \n",
       "1           1  6202db4b61c151e3e1d86cf5d3a75877        196            33   \n",
       "2           2  370f849df7e2b4570548158dfc63a90c        797           114   \n",
       "3           3  4870509d75603c7bd809595252a984d8        181            24   \n",
       "4           4  63248fdafd2df302b57a479289d76105        449            75   \n",
       "\n",
       "   iso_amoun_z2  iso_amoun_z3  iso_amoun_z4  iso_amoun_z5  iso_amoun_z6  \\\n",
       "0            47            43            28            41            29   \n",
       "1            45            38            21            32            35   \n",
       "2           179           144           100           150           143   \n",
       "3            50            25            16            49            29   \n",
       "4           116            52            72            97            58   \n",
       "\n",
       "   iso_areas        ...          vas_z_volume1  vas_z_volume2  vas_z_volume3  \\\n",
       "0       5238        ...                 535765        1104333         762003   \n",
       "1       5290        ...                 475975        1204535         562326   \n",
       "2      19509        ...                 641479        1235065         742397   \n",
       "3       4265        ...                 544285         971626         285907   \n",
       "4      11678        ...                 571762        1263324         654674   \n",
       "\n",
       "   vas_z_volume4  vas_z_volume5  vas_z_volume6  vas_z_volume_1//2  \\\n",
       "0         488646         968148         488200           0.485148   \n",
       "1         434793         838418         597108           0.395152   \n",
       "2         666509        1001041         619150           0.519389   \n",
       "3         487694         797550         381174           0.560180   \n",
       "4         632676        1133022         662144           0.452585   \n",
       "\n",
       "   vas_z_volume_2//3  vas_z_volume_4//5  vas_z_volume_5//6  \n",
       "0           1.449250           0.504722           1.983097  \n",
       "1           2.142058           0.518587           1.404131  \n",
       "2           1.663618           0.665816           1.616799  \n",
       "3           3.398399           0.611490           2.092352  \n",
       "4           1.929699           0.558397           1.711141  \n",
       "\n",
       "[5 rows x 281 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(join(PATH['STAGE_MASKS'],\n",
    "                      'DATAFRAMES', \n",
    "                      'stats_not_full.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
