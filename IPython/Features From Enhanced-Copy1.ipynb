{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../support/')\n",
    "from scipy.ndimage.measurements import label\n",
    "from scipy.ndimage import interpolation\n",
    "from time import time\n",
    "from glob import glob\n",
    "import timeit\n",
    "from os.path import join, basename, isfile\n",
    "from tqdm import tqdm\n",
    "from paths import *\n",
    "from ct_reader import *\n",
    "import dicom\n",
    "from scipy.misc import imresize\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "from paths import *\n",
    "from scipy.ndimage import morphology\n",
    "# import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_ct(path, ret_xy_spacing=False):\n",
    "    patient = read_ct_scan(path)\n",
    "    image = get_pixels_hu(patient)\n",
    "    image[image == image[0,0,0]] = 0\n",
    "    \n",
    "    if ret_xy_spacing:\n",
    "        try:\n",
    "            return image, patient[0].PixelSpacing[0]\n",
    "        except AttributeError:\n",
    "            return image, scan.GetSpacing()[0]\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_nodules(enhanced):\n",
    "    isolated = enhanced.copy()\n",
    "    isolated[(isolated == 4)\n",
    "            |(isolated == 2)\n",
    "            |(isolated == 6)] = 0\n",
    "    isolated, _ = label(isolated)\n",
    "\n",
    "    vascular = enhanced.copy()\n",
    "    vascular[(vascular == 1)\n",
    "            |(vascular == 2)\n",
    "            |(vascular == 3)] = 0\n",
    "    vascular, _ = label(vascular)\n",
    "\n",
    "    plural = enhanced.copy()\n",
    "    plural[(plural == 1)\n",
    "          |(plural == 4)\n",
    "          |(plural == 5)] = 0\n",
    "    plural, _ = label(plural)\n",
    "    return isolated, vascular, plural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mask_features(mask,sp_mask):\n",
    "    volumes = bincount(mask.flatten())\n",
    "    zone_volumes = bincount(sp_mask.flatten())\n",
    "    ans = dict()\n",
    "    for i in range(16):\n",
    "        try:\n",
    "            ans['volume' + str(i)] = volumes[i]\n",
    "        except:\n",
    "            ans['volume' + str(i)] = 0 \n",
    "    for i in range(7):\n",
    "        ans['z_volume' + str(i)] = zone_volumes[i]\n",
    "    ans['l//r'] = volumes[1]  / volumes[2] if(volumes[2]) else 0.0\n",
    "    ans['lungoverlap//l'] = volumes[3] / volumes[1] if(volumes[1]) else 0.0\n",
    "    ans['br_overlap//l'] = volumes[5] / volumes[1] if(volumes[1]) else 0.0\n",
    "    ans['br_overlap//r'] = volumes[6] / volumes[2] if(volumes[2]) else 0.0\n",
    "    ans['tr_overlap//l'] = volumes[9] / volumes[1] if(volumes[1]) else 0.0\n",
    "    ans['tr_overlap//r'] = volumes[10] / volumes[2] if(volumes[2]) else 0.0\n",
    "    ans['br_tr_overlap//tr'] = volumes[12] / volumes[8] if(volumes[8]) else 0.0\n",
    "    ans['z_volume_1//2'] = zone_volumes[1] / zone_volumes[2]\n",
    "    ans['z_volume_2//3'] = zone_volumes[2] / zone_volumes[3]\n",
    "    ans['z_volume_4//5'] = zone_volumes[4] / zone_volumes[5]\n",
    "    ans['z_volume_5//6'] = zone_volumes[5] / zone_volumes[6]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def if_left(mask):\n",
    "    return in1d(mask,[1,3,5,7,9,11,13,15]).reshape(mask.shape)\n",
    "            \n",
    "def if_right(mask):\n",
    "    return in1d(mask,[2,3,6,7,10,11,14,15]).reshape(mask.shape)\n",
    "\n",
    "def split_mask(mask):\n",
    "    mn1 = where(if_left(mask))[0].min()\n",
    "    mx1 = where(if_left(mask))[0].max()\n",
    "    mn2 = where(if_right(mask))[0].min()\n",
    "    mx2 = where(if_right(mask))[0].max()\n",
    "    height1 = int((mx1-mn1)/3.0)\n",
    "    height2 = int((mx2-mn2)/3.0)\n",
    "    mask_zones = zeros(mask.shape)\n",
    "    mask_zones[mn1:mn1+height1,:,:] = 1 \n",
    "    mask_zones[mn1+height1:mn1+2*height1,:,:] = 2\n",
    "    mask_zones[mn1+2*height1:mx1,:,:] = 3\n",
    "    mask_l = if_left(mask)*mask_zones\n",
    "    mask_zones = zeros(mask.shape)\n",
    "    mask_zones[mn2:mn2+height2,:,:] = 4\n",
    "    mask_zones[mn2+height2:mn2+2*height2,:,:] = 5\n",
    "    mask_zones[mn2+2*height2:mx2,:,:] = 6\n",
    "    return (mask_l + if_right(mask) * mask_zones).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge(enhanced, mask):\n",
    "    return 8 * mask + enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collect_stats(enhanced,mask,sp_mask):\n",
    "    prev_time = time()\n",
    "    l_enhanced = enhanced * if_left(mask)\n",
    "    r_enhanced = enhanced * if_right(mask)\n",
    " \n",
    "    \n",
    "#     print('split_mask ',time()-prev_time)\n",
    "#     prev_time = time()\n",
    "    \n",
    "    enh_areas = bincount(enhanced.flatten())[1:]\n",
    "    enh_l_areas = bincount(l_enhanced.flatten())[1:]\n",
    "    enh_r_areas = bincount(r_enhanced.flatten())[1:]\n",
    "    \n",
    "    enh_areas_zones = list()\n",
    "    for i in range(1,7):\n",
    "        enh_areas_zones.append(bincount((enhanced * (sp_mask == i)).flatten())[1:])\n",
    "#     enh_l_areas = concatenate((enh_areas_zones[1][enh_areas_zones[1]>0],\n",
    "#                               enh_areas_zones[2][enh_areas_zones[2]>0],\n",
    "#                               enh_areas_zones[0][enh_areas_zones[0]>0]))\n",
    "#     enh_r_areas = concatenate((enh_areas_zones[4][enh_areas_zones[4]>0],\n",
    "#                               enh_areas_zones[5][enh_areas_zones[5]>0],\n",
    "#                               enh_areas_zones[3][enh_areas_zones[3]>0]))\n",
    "#     enh_areas = concatenate((enh_l_areas,enh_r_areas))\n",
    "#     print('bincounts ',time()-prev_time)\n",
    "#     prev_time = time()\n",
    "    \n",
    "    if not enh_areas.shape[0]:\n",
    "        max_areas = dict()\n",
    "        for i in range(5):\n",
    "            max_areas['max'+str(i)] = 0\n",
    "            max_areas['max_l'+str(i)] = 0\n",
    "            max_areas['max_r'+str(i)] = 0\n",
    "        zone_feats = dict()\n",
    "        for i in range(6):\n",
    "            zone_feats['amoun_z' + str(i+1)] = 0\n",
    "            zone_feats['sumarea_z' + str(i+1)] = 0\n",
    "        enh_comps_after_dil = dict()\n",
    "        for i in range(20):\n",
    "            enh_comps_after_dil['comps_dil'+str(i)] = 0\n",
    "            enh_comps_after_dil['comps_dil_l'+str(i)] = 0\n",
    "            enh_comps_after_dil['comps_dil_r'+str(i)] = 0\n",
    "        ans = dict((('areas', 0), ('amoun', 0), \n",
    "                     ('mean', 0), ('std', 0), ('median', 0), \n",
    "                     ('mean_not_min', 0), \n",
    "                     ('median_not_min', 0), \n",
    "                     ('modes', [0] * 9)))\n",
    "        ans.update(max_areas)\n",
    "        ans.update(enh_comps_after_dil)\n",
    "        ans.update(mask_features(mask,sp_mask))\n",
    "        ans.update(zone_feats)\n",
    "        return ans\n",
    "    \n",
    "    enh_amoun = enh_areas[enh_areas > 0].shape[0]\n",
    "    enh_amoun_l = enh_l_areas[enh_l_areas > 0].shape[0]\n",
    "    enh_amoun_r = enh_r_areas[enh_r_areas > 0].shape[0]\n",
    "    enh_amoun_zones = [x[x > 0].shape[0] for x in enh_areas_zones]\n",
    "    enh_area_sum_zones = [x[x > 0].sum() for x in enh_areas_zones]\n",
    "    \n",
    "    zone_feats = dict()\n",
    "    for i in range(6):\n",
    "        zone_feats['amoun_z' + str(i+1)] = enh_amoun_zones[i]\n",
    "        zone_feats['sumarea_z' + str(i+1)] = enh_area_sum_zones[i]\n",
    "    \n",
    "    enh_mean = mean(enh_areas)\n",
    "    enh_std = std(enh_areas)\n",
    "    enh_sort_areas = sorted(enh_areas[enh_areas > 0],reverse=True)\n",
    "    enh_sort_areas_l = sorted(enh_l_areas[enh_l_areas > 0],reverse=True)\n",
    "    enh_sort_areas_r = sorted(enh_r_areas[enh_r_areas > 0],reverse=True)\n",
    "    max_areas = dict()\n",
    "    for i in range(5):\n",
    "        try:\n",
    "            max_areas['max'+str(i)] = enh_sort_areas[i]\n",
    "        except:\n",
    "            max_areas['max'+str(i)] = 0 \n",
    "        try:\n",
    "            max_areas['max_l'+str(i)] = enh_sort_areas_l[i]\n",
    "        except:\n",
    "            max_areas['max_l'+str(i)] = 0    \n",
    "        try:\n",
    "            max_areas['max_r'+str(i)] = enh_sort_areas_r[i]\n",
    "        except:\n",
    "            max_areas['max_l'+str(i)] = 0\n",
    "    \n",
    "    enh_median = median(enh_areas)\n",
    "    enh_mean_not_min = enh_areas[enh_areas != enh_areas.min()].mean()\n",
    "    enh_median_not_min = median(enh_areas[enh_areas != enh_areas.min()])\n",
    "    modes = [2, 3, 4, 5, 6, 9, 12, 19, 37, 1e7]\n",
    "    enh_modes = [sum((enh_areas >= modes[i - 1]) \n",
    "                 & (modes[i] > enh_areas))\n",
    "                for i in range(1, len(modes))]\n",
    "    \n",
    "#     print('stats ',time()-prev_time)\n",
    "#     prev_time = time()\n",
    "    \n",
    "    img = enhanced.copy()\n",
    "    enh_comps_after_dil = dict()\n",
    "    iter_num = 1\n",
    "    for i in range(iter_num):\n",
    "        labeled,label_num = label(img)\n",
    "        enh_comps_after_dil['comps_dil'+str(i)] = label_num\n",
    "        enh_comps_after_dil['comps_dil_l'+str(i)] = len(unique(labeled*if_left(mask)))\n",
    "        enh_comps_after_dil['comps_dil_r'+str(i)] = len(unique(labeled*if_right(mask)))\n",
    "        img = morphology.binary_dilation(img,structure=ones((5,5,5)))\n",
    "    labeled,label_num = label(img)\n",
    "    enh_comps_after_dil['comps_dil'+str(iter_num)] = label_num\n",
    "    enh_comps_after_dil['comps_dil_l'+str(iter_num)] = len(unique(labeled*if_left(mask)))\n",
    "    enh_comps_after_dil['comps_dil_r'+str(iter_num)] = len(unique(labeled*if_right(mask)))\n",
    "\n",
    "#     print('dil ',time()-prev_time)\n",
    "#     prev_time = time()\n",
    "    \n",
    "    \n",
    "    ans = dict((('areas', sum(enh_areas)), ('amoun', enh_amoun), \n",
    "                 ('mean', enh_mean), ('std', enh_std), ('median', enh_median), \n",
    "                 ('mean_not_min', enh_mean_not_min), \n",
    "                 ('median_not_min', enh_median_not_min),\n",
    "                 ('modes', enh_modes)))\n",
    "    ans.update(max_areas)\n",
    "    ans.update(enh_comps_after_dil)\n",
    "    ans.update(mask_features(mask,sp_mask))\n",
    "    ans.update(zone_feats)\n",
    "\n",
    "#     print('mask_feats ',time()-prev_time)\n",
    "#     prev_time = time()\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def operate(path):\n",
    "    try:\n",
    "        enhanced = load(join(PATH['STAGE_ENHANCED'], \n",
    "                             path + '.npy'))\n",
    "        mask = load(join(PATH['STAGE_MASKS'], \n",
    "                             path + '.npy'))\n",
    "\n",
    "        zoomfactor = [w / float(f) for w, f in zip(enhanced.shape, mask.shape)]\n",
    "        mask = interpolation.zoom(mask, zoom=zoomfactor, order = 0, mode = 'nearest')\n",
    "        isolated, vascular, plural = label_nodules(enhanced)\n",
    "        sp_mask = split_mask(mask)\n",
    "        save(join(PATH['STAGE_MASKS'], path), merge(enhanced,mask))\n",
    "        return (path, collect_stats(isolated,mask,sp_mask)),\\\n",
    "                (path, collect_stats(vascular,mask,sp_mask)),\\\n",
    "                (path, collect_stats(plural,mask,sp_mask))\n",
    "    except:\n",
    "        pass\n",
    "        return ((path, None), (path, None), (path, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "patients = set([basename(path)[:32] for path in glob(join(PATH['STAGE_ENHANCED'], '*'))])\n",
    "patients = patients.difference(pickle.load(open(join(PATH['STAGE_MASKS'], 'still_erroneus_ncrash'), 'rb')))\n",
    "stats = list()\n",
    "CPU = 1\n",
    "with Pool(CPU) as pool:\n",
    "    stats = pool.map(operate, list(patients)[-5:])\n",
    "    \n",
    "print('Done.')\n",
    "path = join(PATH['STAGE_MASKS'], 'DATAFRAMES')\n",
    "pickle.dump(stats, open(join(path, 'merged_stats'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('e62c65f23653e8439a5176fe778cf8b1', None),\n",
       "  ('e62c65f23653e8439a5176fe778cf8b1', None),\n",
       "  ('e62c65f23653e8439a5176fe778cf8b1', None))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
